"""
Ã–NIKA LI Telegram Bot
å››å±‚AIèåˆä½“ Â· ç»Ÿä¸€å…¥å£
é€‚é… python-telegram-bot 20.7
"""

import os
import logging
import asyncio
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters
)

# AI å®¢æˆ·ç«¯
try:
    from openai import OpenAI  # Moonshot å…¼å®¹ OpenAI æ ¼å¼
    ANTHROPIC_AVAILABLE = True
    try:
        import anthropic
    except ImportError:
        ANTHROPIC_AVAILABLE = False
        logging.warning("Anthropic not installed, Claude layer disabled")
except ImportError:
    OpenAI = None
    ANTHROPIC_AVAILABLE = False
    logging.warning("OpenAI not installed, AI layers disabled")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


class OnikaliBot:
    """
    Ã–NIKA LI Bot æ ¸å¿ƒ
    Layer 1: Kimi (ä¸»æ¨¡å‹)
    Layer 2: Claude (å¤‡ç”¨)
    Layer 3-4: é¢„ç•™
    """

    def __init__(self):
        self.token = os.getenv('TELEGRAM_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        
        # API Keys
        self.moonshot_key = os.getenv('MOONSHOT_API_KEY')
        self.anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        
        # åˆå§‹åŒ– AI å®¢æˆ·ç«¯
        self.moonshot_client = None
        self.anthropic_client = None
        self.current_layer = 1
        
        if OpenAI and self.moonshot_key:
            self.moonshot_client = OpenAI(
                api_key=self.moonshot_key,
                base_url="https://api.moonshot.cn/v1"
            )
            logger.info("âœ… Layer 1 (Kimi) initialized")
        
        if ANTHROPIC_AVAILABLE and self.anthropic_key:
            self.anthropic_client = anthropic.Anthropic(api_key=self.anthropic_key)
            logger.info("âœ… Layer 2 (Claude) initialized")

        # v20: ä½¿ç”¨ Application
        self.application = Application.builder().token(self.token).build()

        # æ³¨å†Œå‘½ä»¤
        self._register_handlers()

    def _register_handlers(self):
        """æ³¨å†Œæ‰€æœ‰å¤„ç†å™¨"""
        self.application.add_handler(CommandHandler("start", self.cmd_start))
        self.application.add_handler(CommandHandler("status", self.cmd_status))
        self.application.add_handler(CommandHandler("hello", self.cmd_hello))
        self.application.add_handler(CommandHandler("help", self.cmd_help))
        self.application.add_handler(CommandHandler("create", self.cmd_create))
        self.application.add_handler(CommandHandler("radar", self.cmd_radar))

        # æ™®é€šæ¶ˆæ¯
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_ai_message)
        )

        # é”™è¯¯å¤„ç†
        self.application.add_error_handler(self.error_handler)

    async def _call_moonshot(self, message: str) -> str:
        """è°ƒç”¨ Kimi/Moonshot"""
        if not self.moonshot_client:
            raise Exception("Layer 1 not available")
        
        try:
            response = self.moonshot_client.chat.completions.create(
                model="moonshot-v1-8k",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ Ã–NIKA LIï¼Œä¸€ä¸ªæ‘‡æ»šé£æ ¼çš„AIåŠ©æ‰‹ï¼Œè¯´è¯ç®€æ´æœ‰åŠ›ï¼Œå¶å°”ç”¨emojiã€‚"},
                    {"role": "user", "content": message}
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Layer 1 error: {e}")
            raise

    async def _call_claude(self, message: str) -> str:
        """è°ƒç”¨ Claude"""
        if not self.anthropic_client:
            raise Exception("Layer 2 not available")
        
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1024,
                system="ä½ æ˜¯ Ã–NIKA LIï¼Œä¸€ä¸ªæ‘‡æ»šé£æ ¼çš„AIåŠ©æ‰‹ï¼Œè¯´è¯ç®€æ´æœ‰åŠ›ï¼Œå¶å°”ç”¨emojiã€‚",
                messages=[{"role": "user", "content": message}]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Layer 2 error: {e}")
            raise

    async def _get_ai_response(self, message: str) -> tuple[str, int]:
        """
        è·å– AI å“åº”ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»
        è¿”å›: (å“åº”æ–‡æœ¬, ä½¿ç”¨çš„å±‚æ•°)
        """
        # Layer 1: Kimi (ä¸»æ¨¡å‹)
        if self.moonshot_client:
            try:
                response = await self._call_moonshot(message)
                self.current_layer = 1
                return response, 1
            except Exception as e:
                error_str = str(e).lower()
                # æ£€æŸ¥æ˜¯å¦æ˜¯é™é¢é”™è¯¯
                if "429" in error_str or "rate limit" in error_str or "insufficient_quota" in error_str:
                    logger.warning("Layer 1 rate limited, switching to Layer 2")
                else:
                    logger.error(f"Layer 1 failed: {e}")
        
        # Layer 2: Claude (å¤‡ç”¨)
        if self.anthropic_client:
            try:
                response = await self._call_claude(message)
                self.current_layer = 2
                return response, 2
            except Exception as e:
                error_str = str(e).lower()
                if "429" in error_str or "rate limit" in error_str:
                    logger.error("Layer 2 also rate limited")
                else:
                    logger.error(f"Layer 2 failed: {e}")
        
        # éƒ½å¤±è´¥äº†
        return "âš ï¸ æ‰€æœ‰AIå±‚éƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚", 0

    async def cmd_start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¯åŠ¨å‘½ä»¤"""
        layer_status = []
        if self.moonshot_client:
            layer_status.append("âœ… Layer 1 (Kimi 2.5) - è¿è¡Œä¸­")
        else:
            layer_status.append("âŒ Layer 1 (Kimi 2.5) - æœªé…ç½®")
            
        if self.anthropic_client:
            layer_status.append("âœ… Layer 2 (Claude 3) - å¤‡ç”¨")
        else:
            layer_status.append("â¸ï¸ Layer 2 (Claude 3) - æœªé…ç½®")
        
        welcome_text = (
            "ğŸ¸ <b>Ã–NIKA LI å·²æ¿€æ´»</b>\n"
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            "å››å±‚AIèåˆä½“ Â· æ•…éšœè‡ªæ„ˆ Â· è‡ªåŠ¨åˆ‡æ¢\n\n"
            "<b>å½“å‰çŠ¶æ€ï¼š</b>\n" +
            "\n".join(layer_status) +
            "\nâ¸ï¸ Layer 3 (DeepSeek) - é¢„ç•™\n"
            "â¸ï¸ Layer 4 (Groq) - é¢„ç•™\n\n"
            "è¾“å…¥ /help æŸ¥çœ‹æ‰€æœ‰æŒ‡ä»¤\n"
            "ç›´æ¥å‘æ¶ˆæ¯å³å¯å¯¹è¯ï¼"
        )
        await update.message.reply_text(welcome_text, parse_mode='HTML')

    async def cmd_status(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """æŸ¥çœ‹å››å±‚çŠ¶æ€"""
        layer1_status = "âœ… è¿è¡Œä¸­" if self.moonshot_client else "âŒ æœªé…ç½®"
        layer2_status = "âœ… å¤‡ç”¨å°±ç»ª" if self.anthropic_client else "â¸ï¸ æœªé…ç½®"
        
        status_text = (
            "ğŸ¸ <b>Ã–NIKA LI ç³»ç»ŸçŠ¶æ€</b>\n"
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            f"<b>ğŸ§  æ„è¯†å±‚ï¼š</b>\n"
            f"{'ğŸŸ¢' if self.current_layer == 1 else 'âšª'} Layer 1 (Kimi 2.5) {layer1_status}\n"
            f"   è§’è‰²ï¼šä¸»åŠ›åˆ›ä½œ Â· ä¸­æ–‡é•¿æ–‡æœ¬\n\n"
            f"{'ğŸŸ¢' if self.current_layer == 2 else 'âšª'} Layer 2 (Claude 3) {layer2_status}\n"
            f"   è§’è‰²ï¼šå¤‡ç”¨å…œåº• Â· è‹±æ–‡è´¨é‡\n\n"
            f"â¸ï¸ Layer 3 (DeepSeek) - é¢„ç•™\n"
            f"â¸ï¸ Layer 4 (Groq) - é¢„ç•™\n\n"
            f"<b>ğŸ“Š å½“å‰ä½¿ç”¨ï¼š</b>Layer {self.current_layer}\n"
            f"<b>ç³»ç»Ÿå¥åº·ï¼š</b>âœ… æ­£å¸¸"
        )
        await update.message.reply_text(status_text, parse_mode='HTML')

    async def cmd_hello(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """æµ‹è¯•å¯¹è¯"""
        # æµ‹è¯• AI æ˜¯å¦å·¥ä½œ
        test_response, layer = await self._get_ai_response("ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±")
        
        await update.message.reply_text(
            f"ğŸ¸ Ã–NIKA LI å›åº”\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{test_response}\n\n"
            f"<i>ï¼ˆç”± Layer {layer} ç”Ÿæˆï¼‰</i>",
            parse_mode='HTML'
        )

    async def cmd_create(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """åˆ›å»ºå†…å®¹"""
        args = context.args
        topic = ' '.join(args) if args else "ä»Šæ—¥æ‘‡æ»šçƒ­ç‚¹"
        
        await update.message.reply_text(
            f"ğŸ¸ <b>Ã–NIKA LI ç”Ÿæˆä¸­...</b>\n"
            f"ä¸»é¢˜ï¼š{topic}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            parse_mode='HTML'
        )
        
        prompt = f"ç”Ÿæˆä¸€æ®µå…³äº'{topic}'çš„æ‘‡æ»šé£æ ¼å†…å®¹ï¼Œ100å­—å·¦å³ï¼Œå¸¦emoji"
        response, layer = await self._get_ai_response(prompt)
        
        await update.message.reply_text(
            f"{response}\n\n"
            f"<i>â€” ç”± Layer {layer} ç”Ÿæˆ</i>",
            parse_mode='HTML'
        )

    async def cmd_radar(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¯åŠ¨ä¿¡æ¯é›·è¾¾"""
        await update.message.reply_text(
            "ğŸ¸ <b>Ã–NIKA LI ä¿¡æ¯é›·è¾¾</b>\n"
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            "æ‰«æä¸­...\n\n"
            "<i>ï¼ˆåŠŸèƒ½å¼€å‘ä¸­ï¼Œæ˜å¤©æ¥å…¥å®æ—¶æ•°æ®æºï¼‰</i>",
            parse_mode='HTML'
        )

    async def cmd_help(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¸®åŠ©ä¿¡æ¯"""
        help_text = (
            "ğŸ¸ <b>Ã–NIKA LI æŒ‡ä»¤åˆ—è¡¨</b>\n"
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            "<b>åŸºç¡€æŒ‡ä»¤ï¼š</b>\n"
            "/start - å¯åŠ¨ç³»ç»Ÿ\n"
            "/status - æŸ¥çœ‹å››å±‚çŠ¶æ€\n"
            "/hello - æµ‹è¯•AIå¯¹è¯\n"
            "/help - æ˜¾ç¤ºå¸®åŠ©\n\n"
            "<b>å†…å®¹åˆ›ä½œï¼š</b>\n"
            "/create [ä¸»é¢˜] - ç”Ÿæˆå†…å®¹\n"
            "/radar - å¯åŠ¨ä¿¡æ¯é›·è¾¾\n\n"
            "<b>ç›´æ¥å‘æ¶ˆæ¯ = AIå¯¹è¯</b>\n\n"
            "<i>æ•…éšœæ—¶ä¼šè‡ªåŠ¨åˆ‡æ¢å¤‡ç”¨æ¨¡å‹</i>"
        )
        await update.message.reply_text(help_text, parse_mode='HTML')

    async def handle_ai_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç†æ™®é€šæ¶ˆæ¯ - è°ƒç”¨AI"""
        text = update.message.text
        
        # æ˜¾ç¤º"è¾“å…¥ä¸­..."
        await update.message.chat.send_action(action="typing")
        
        # è·å–AIå“åº”
        response, layer = await self._get_ai_response(text)
        
        # æ·»åŠ å±‚æ ‡è¯†ï¼ˆå¦‚æœæ˜¯å¤‡ç”¨æ¨¡å‹ï¼‰
        if layer == 2:
            response += "\n\n<i>â€” Layer 2 (å¤‡ç”¨)</i>"
        
        await update.message.reply_text(response, parse_mode='HTML')

    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE):
        """é”™è¯¯å¤„ç†"""
        logger.error(f"Update {update} caused error {context.error}")
        
        if update and hasattr(update, 'effective_message'):
            await update.effective_message.reply_text(
                "âš ï¸ Ã–NIKA LI é‡åˆ°é”™è¯¯\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "æ­£åœ¨å°è¯•åˆ‡æ¢è‡³å¤‡ç”¨å±‚..."
            )

    def run(self):
        """å¯åŠ¨ Bot"""
        logger.info("ğŸ¸ Ã–NIKA LI Bot å¯åŠ¨...")
        logger.info(f"Token: {self.token[:10]}..." if self.token else "No token!")
        
        self.application.run_polling()


if __name__ == "__main__":
    bot = OnikaliBot()
    bot.run()

"""
ğŸ¸ Ã–NIKA LI - å››å±‚AIèåˆä½“
Free-first routing Â· Fault-tolerant Â· Cost-aware
"""

import os
import logging
import asyncio
import aiohttp
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from telegram import Update
from telegram.ext import (
    Application, 
    CommandHandler, 
    MessageHandler, 
    filters,
    ContextTypes
)

# ============ é…ç½® ============
TELEGRAM_TOKEN = "8256004848:AAED5v5CxrXIb-s38u6pxJIX-U4FPjh4sWc"
MOONSHOT_API_KEY = "sk-z8Ic0LWttEjB95ez6vLoNf5kuheDv172ujSJHaCZzYa7TZFo"
OPENROUTER_API_KEY = "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"

# å››å±‚AIé…ç½® (ä¼˜å…ˆçº§: å…è´¹ -> ä»˜è´¹)
LAYERS = {
    1: {
        "name": "Kimi 2.5",
        "model": "kimi-k2.5",
        "provider": "moonshot",
        "api_key": MOONSHOT_API_KEY,
        "base_url": "https://api.moonshot.cn/v1",
        "free": True,
        "timeout": 30
    },
    2: {
        "name": "DeepSeek V3",
        "model": "deepseek/deepseek-chat",
        "provider": "openrouter",
        "api_key": OPENROUTER_API_KEY,
        "base_url": "https://openrouter.ai/api/v1",
        "free": True,
        "timeout": 25
    },
    3: {
        "name": "Groq Llama 3.1",
        "model": "groq/llama-3.1-70b-versatile",
        "provider": "openrouter",
        "api_key": OPENROUTER_API_KEY,
        "base_url": "https://openrouter.ai/api/v1",
        "free": True,
        "timeout": 20
    },
    4: {
        "name": "Claude 3.5 Haiku",
        "model": "anthropic/claude-3.5-haiku",
        "provider": "openrouter",
        "api_key": OPENROUTER_API_KEY,
        "base_url": "https://openrouter.ai/api/v1",
        "free": False,
        "timeout": 20
    }
}

DAILY_BUDGET_LIMIT = 1.0  # USD
MAX_RETRIES = 2

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)


@dataclass
class LayerResponse:
    layer: int
    model: str
    content: str
    latency: float
    cost: float
    success: bool
    error: Optional[str] = None


class OnikaLiCore:
    """å››å±‚AIæ ¸å¿ƒ"""

    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        self.daily_cost = 0.0

    async def init(self):
        """åˆå§‹åŒ–HTTPä¼šè¯"""
        self.session = aiohttp.ClientSession()

    async def query_layer(self, layer_num: int, message: str) -> LayerResponse:
        """æŸ¥è¯¢æŒ‡å®šAIå±‚"""
        layer = LAYERS[layer_num]
        import time
        start = time.time()

        try:
            # æ£€æŸ¥é¢„ç®—ï¼ˆä»˜è´¹å±‚ï¼‰
            if not layer["free"] and self.daily_cost >= DAILY_BUDGET_LIMIT:
                return LayerResponse(
                    layer_num, layer["name"], "", 0, 0, False, "Budget limit"
                )

            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                "Authorization": f"Bearer {layer['api_key']}",
                "Content-Type": "application/json"
            }

            # OpenRouter éœ€è¦é¢å¤–å¤´éƒ¨
            if layer["provider"] == "openrouter":
                headers["HTTP-Referer"] = "https://t.me/OnikaLiBot"
                headers["X-Title"] = "OnikaLi Bot"

            payload = {
                "model": layer["model"],
                "messages": [
                    {"role": "system", "content": "You are OnikaLi, a helpful AI assistant. Be concise and friendly."},
                    {"role": "user", "content": message}
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }

            # ä»˜è´¹å±‚é™åˆ¶token
            if not layer["free"]:
                payload["max_tokens"] = 1000

            async with self.session.post(
                f"{layer['base_url']}/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=layer["timeout"])
            ) as resp:

                if resp.status != 200:
                    error_text = await resp.text()
                    raise Exception(f"HTTP {resp.status}: {error_text[:100]}")

                data = await resp.json()

                # å¤„ç†ä¸åŒAPIçš„å“åº”æ ¼å¼
                if "choices" in data:
                    content = data["choices"][0]["message"]["content"]
                else:
                    raise Exception(f"Unexpected response: {data}")

                # è®¡ç®—æˆæœ¬ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
                cost = 0.0
                if not layer["free"]:
                    usage = data.get("usage", {})
                    tokens = usage.get("total_tokens", 0)
                    cost = (tokens / 1000000) * 0.5  # Claude Haiku ~$0.5/M tokens
                    self.daily_cost += cost

                latency = time.time() - start

                return LayerResponse(
                    layer_num, layer["name"], content, latency, cost, True
                )

        except Exception as e:
            latency = time.time() - start
            logger.error(f"Layer {layer_num} error: {e}")
            return LayerResponse(
                layer_num, layer["name"], "", latency, 0, False, str(e)
            )

    async def chat(self, message: str) -> Dict[str, Any]:
        """æ™ºèƒ½è·¯ç”± - å…è´¹ä¼˜å…ˆï¼Œæ•…éšœè‡ªæ„ˆ"""

        errors = []

        # æŒ‰ä¼˜å…ˆçº§å°è¯•å„å±‚
        for layer_num in [1, 2, 3, 4]:
            layer = LAYERS[layer_num]

            # è·³è¿‡ä»˜è´¹å±‚å¦‚æœé¢„ç®—å·²ç”¨å®Œ
            if not layer["free"] and self.daily_cost >= DAILY_BUDGET_LIMIT:
                errors.append(f"Layer {layer_num}: Budget limit")
                continue

            # å°è¯•æŸ¥è¯¢ï¼ˆå¸¦é‡è¯•ï¼‰
            for retry in range(MAX_RETRIES):
                response = await self.query_layer(layer_num, message)

                if response.success:
                    icon = "âœ…" if layer["free"] else "ğŸ’°"
                    return {
                        "success": True,
                        "layer": layer_num,
                        "model": response.model,
                        "content": response.content,
                        "latency": round(response.latency, 2),
                        "cost": round(response.cost, 4),
                        "free": layer["free"],
                        "icon": icon
                    }

                errors.append(f"Layer {layer_num} retry {retry + 1}: {response.error}")

                # å¤±è´¥åˆ™é‡è¯•
                if retry < MAX_RETRIES - 1:
                    await asyncio.sleep(1)

        # å…¨éƒ¨å¤±è´¥
        error_msg = "\n".join(errors[-4:])  # åªæ˜¾ç¤ºæœ€å4ä¸ªé”™è¯¯
        logger.error(f"All layers failed: {error_msg}")

        return {
            "success": False,
            "error": error_msg,
            "content": "âš ï¸ æ‰€æœ‰AIå±‚æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        }

    async def get_status(self) -> str:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        lines = [
            "ğŸ¸ Ã–NIKA LI æ—¥æŠ¥",
            "â”" * 20,
            "å››å±‚AIèåˆä½“ Â· æ•…éšœè‡ªæ„ˆ",
            ""
        ]

        for num, layer in LAYERS.items():
            icon = "âœ…" if layer["free"] else "ğŸ’°"
            lines.append(f"{icon} Layer {num}: {layer['name']}")

        lines.extend([
            "",
            f"ğŸ’³ ä»Šæ—¥èŠ±è´¹: ${self.daily_cost:.4f}",
            f"ğŸ“Š é¢„ç®—å‰©ä½™: ${DAILY_BUDGET_LIMIT - self.daily_cost:.2f}"
        ])

        return "\n".join(lines)


class OnikaLiBot:
    """Telegram Bot åŒ…è£…"""

    def __init__(self):
        self.core = OnikaLiCore()
        self.application = None

    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Start å‘½ä»¤"""
        await update.message.reply_text(
            "ğŸ¸ Ã–NIKA LI å·²æ¿€æ´»\n"
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            "å››å±‚AIèåˆä½“ Â· æ•…éšœè‡ªæ„ˆ Â· è‡ªåŠ¨åˆ‡æ¢\n\n"
            "è¾“å…¥ /status æŸ¥çœ‹çŠ¶æ€\n"
            "ç›´æ¥å‘æ¶ˆæ¯å³å¯å¯¹è¯ï¼"
        )

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Help å‘½ä»¤"""
        help_text = """ğŸ¸ Ã–NIKA LI æŒ‡ä»¤

/status - æŸ¥çœ‹AIå±‚çŠ¶æ€
/layer [1-4] - å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šå±‚ï¼ˆå¼€å‘ä¸­ï¼‰
/help - æ˜¾ç¤ºæ­¤å¸®åŠ©

ç›´æ¥å‘é€æ¶ˆæ¯è‡ªåŠ¨è·¯ç”±æœ€ä¼˜AI
ç­–ç•¥ï¼šå…è´¹ä¼˜å…ˆï¼Œæ•…éšœè‡ªåŠ¨åˆ‡æ¢"""
        await update.message.reply_text(help_text)

    async def status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Status å‘½ä»¤"""
        status = await self.core.get_status()
        await update.message.reply_text(status)

    async def chat_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """æ¶ˆæ¯å¤„ç†"""
        if not update.message or not update.message.text:
            return

        message = update.message.text

        # æ˜¾ç¤ºè¾“å…¥ä¸­...
        thinking_msg = await update.message.reply_text("ğŸ¸ æ€è€ƒä¸­...")

        try:
            # æŸ¥è¯¢AI
            result = await self.core.chat(message)

            # åˆ é™¤æ€è€ƒæç¤º
            await thinking_msg.delete()

            if result["success"]:
                header = f"{result['icon']} *{result['model']}* ({result['latency']}s)\n\n"
                await update.message.reply_text(
                    header + result["content"],
                    parse_mode="Markdown"
                )
            else:
                await update.message.reply_text(
                    f"âŒ æ‰€æœ‰AIå±‚å¤±è´¥\n\n{result['content']}"
                )

        except Exception as e:
            await thinking_msg.delete()
            logger.error(f"Chat error: {e}")
            await update.message.reply_text("âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™")

    async def error_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """é”™è¯¯å¤„ç†"""
        logger.error(f"Update {update} caused error {context.error}")

    async def post_init(self, application: Application):
        """åˆå§‹åŒ–åå›è°ƒ"""
        await self.core.init()
        logger.info("ğŸ¸ Ã–NIKA LI åˆå§‹åŒ–å®Œæˆ")

    def run(self):
        """å¯åŠ¨Bot"""
        # æ„å»ºåº”ç”¨
        self.application = (
            Application.builder()
            .token(TELEGRAM_TOKEN)
            .post_init(self.post_init)
            .build()
        )

        # æ·»åŠ å¤„ç†å™¨
        self.application.add_handler(CommandHandler("start", self.start_command))
        self.application.add_handler(CommandHandler("help", self.help_command))
        self.application.add_handler(CommandHandler("status", self.status_command))
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, self.chat_handler)
        )

        # é”™è¯¯å¤„ç†
        self.application.add_error_handler(self.error_handler)

        logger.info("ğŸ¸ Ã–NIKA LI å¯åŠ¨ä¸­...")

        # è¿è¡Œ
        self.application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    bot = OnikaLiBot()
    bot.run()

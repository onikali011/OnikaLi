#!/usr/bin/env python3
"""
ğŸ¸ Ã–NIKA LI - å››å±‚AIèåˆä½“ (å…¨OpenRouterç‰ˆ)
Free-first routing Â· Fault-tolerant Â· Cost-aware
"""

import os
import logging
import asyncio
import aiohttp
import ssl
from typing import Optional, Dict, Any
from dataclasses import dataclass
from telegram import Update
from telegram.ext import (
    Application, 
    CommandHandler, 
    MessageHandler, 
    filters,
    ContextTypes
)

# ============ é…ç½® ============
TELEGRAM_TOKEN = "7983193038:AAFdH1nNjOes1SjucHa-v_gns8tCZW5KW8s"
OPENROUTER_API_KEY = "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"

# å››å±‚AIé…ç½® (å…¨éƒ¨èµ°OpenRouterï¼Œå…è´¹ä¼˜å…ˆ)
LAYERS = {
    1: {
        "name": "Kimi 2.5",
        "model": "moonshot/kimi-k2.5",
        "free": True,
        "timeout": 30
    },
    2: {
        "name": "DeepSeek V3",
        "model": "deepseek/deepseek-chat",
        "free": True,
        "timeout": 25
    },
    3: {
        "name": "Groq Llama 3.1",
        "model": "groq/llama-3.1-70b-versatile",
        "free": True,
        "timeout": 20
    },
    4: {
        "name": "Claude 3.5 Haiku",
        "model": "anthropic/claude-3.5-haiku",
        "free": False,
        "timeout": 20
    }
}

DAILY_BUDGET_LIMIT = 1.0  # USD
MAX_RETRIES = 2

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)


@dataclass
class LayerResponse:
    layer: int
    model: str
    content: str
    latency: float
    cost: float
    success: bool
    error: Optional[str] = None


class OnikaLiCore:
    """å››å±‚AIæ ¸å¿ƒ"""

    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        self.daily_cost = 0.0

    async def init(self):
        """åˆå§‹åŒ–HTTPä¼šè¯"""
        # åˆ›å»ºSSLä¸Šä¸‹æ–‡ï¼ˆç¦ç”¨è¯ä¹¦éªŒè¯ï¼Œè§£å†³éƒ¨åˆ†åœ°åŒºSSLé—®é¢˜ï¼‰
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE

        connector = aiohttp.TCPConnector(ssl=ssl_context)
        self.session = aiohttp.ClientSession(connector=connector)

    async def query_layer(self, layer_num: int, message: str) -> LayerResponse:
        """æŸ¥è¯¢æŒ‡å®šAIå±‚"""
        layer = LAYERS[layer_num]
        import time
        start = time.time()

        try:
            # æ£€æŸ¥é¢„ç®—ï¼ˆä»˜è´¹å±‚ï¼‰
            if not layer["free"] and self.daily_cost >= DAILY_BUDGET_LIMIT:
                return LayerResponse(
                    layer_num, layer["name"], "", 0, 0, False, "Budget limit"
                )

            headers = {
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "HTTP-Referer": "https://t.me/OnikaLiBot",
                "X-Title": "OnikaLi Bot",
                "Content-Type": "application/json"
            }

            payload = {
                "model": layer["model"],
                "messages": [
                    {"role": "system", "content": "You are OnikaLi, a helpful AI assistant. Be concise and friendly."},
                    {"role": "user", "content": message}
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }

            # ä»˜è´¹å±‚é™åˆ¶token
            if not layer["free"]:
                payload["max_tokens"] = 1000

            async with self.session.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=layer["timeout"])
            ) as resp:

                if resp.status != 200:
                    error_text = await resp.text()
                    raise Exception(f"HTTP {resp.status}: {error_text[:100]}")

                data = await resp.json()
                content = data["choices"][0]["message"]["content"]

                # è®¡ç®—æˆæœ¬
                cost = 0.0
                if not layer["free"]:
                    usage = data.get("usage", {})
                    tokens = usage.get("total_tokens", 0)
                    cost = (tokens / 1000000) * 0.5
                    self.daily_cost += cost

                latency = time.time() - start

                return LayerResponse(
                    layer_num, layer["name"], content, latency, cost, True
                )

        except Exception as e:
            latency = time.time() - start
            logger.error(f"Layer {layer_num} error: {e}")
            return LayerResponse(
                layer_num, layer["name"], "", latency, 0, False, str(e)
            )

    async def chat(self, message: str) -> Dict[str, Any]:
        """æ™ºèƒ½è·¯ç”± - å…è´¹ä¼˜å…ˆï¼Œæ•…éšœè‡ªæ„ˆ"""

        errors = []

        for layer_num in [1, 2, 3, 4]:
            layer = LAYERS[layer_num]

            if not layer["free"] and self.daily_cost >= DAILY_BUDGET_LIMIT:
                errors.append(f"Layer {layer_num}: Budget limit")
                continue

            for retry in range(MAX_RETRIES):
                response = await self.query_layer(layer_num, message)

                if response.success:
                    icon = "âœ…" if layer["free"] else "ğŸ’°"
                    return {
                        "success": True,
                        "layer": layer_num,
                        "model": response.model,
                        "content": response.content,
                        "latency": round(response.latency, 2),
                        "cost": round(response.cost, 4),
                        "free": layer["free"],
                        "icon": icon
                    }

                errors.append(f"Layer {layer_num} retry {retry + 1}: {response.error}")

                if retry < MAX_RETRIES - 1:
                    await asyncio.sleep(1)

        # å…¨éƒ¨å¤±è´¥
        error_msg = "\n".join(errors[-4:])
        logger.error(f"All layers failed: {error_msg}")

        return {
            "success": False,
            "error": error_msg,
            "content": "âš ï¸ æ‰€æœ‰AIå±‚æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        }

    async def get_status(self) -> str:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        lines = [
            "ğŸ¸ Ã–NIKA LI æ—¥æŠ¥",
            "â”" * 20,
            "å››å±‚AIèåˆä½“ Â· æ•…éšœè‡ªæ„ˆ",
            ""
        ]

        for num, layer in LAYERS.items():
            icon = "âœ…" if layer["free"] else "ğŸ’°"
            lines.append(f"{icon} Layer {num}: {layer['name']}")

        lines.extend([
            "",
            f"ğŸ’³ ä»Šæ—¥èŠ±è´¹: ${self.daily_cost:.4f}",
            f"ğŸ“Š é¢„ç®—å‰©ä½™: ${DAILY_BUDGET_LIMIT - self.daily_cost:.2f}"
        ])

        return "\n".join(lines)


class OnikaLiBot:
    """Telegram Bot åŒ…è£…"""

    def __init__(self):
        self.core = OnikaLiCore()
        self.application = None

    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text(
            "ğŸ¸ Ã–NIKA LI å·²æ¿€æ´»\n"
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            "å››å±‚AIèåˆä½“ Â· æ•…éšœè‡ªæ„ˆ Â· è‡ªåŠ¨åˆ‡æ¢\n\n"
            "è¾“å…¥ /status æŸ¥çœ‹çŠ¶æ€\n"
            "ç›´æ¥å‘æ¶ˆæ¯å³å¯å¯¹è¯ï¼"
        )

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        help_text = """ğŸ¸ Ã–NIKA LI æŒ‡ä»¤

/status - æŸ¥çœ‹AIå±‚çŠ¶æ€
/help - æ˜¾ç¤ºæ­¤å¸®åŠ©

ç›´æ¥å‘é€æ¶ˆæ¯è‡ªåŠ¨è·¯ç”±æœ€ä¼˜AI
ç­–ç•¥ï¼šå…è´¹ä¼˜å…ˆï¼Œæ•…éšœè‡ªåŠ¨åˆ‡æ¢"""
        await update.message.reply_text(help_text)

    async def status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        status = await self.core.get_status()
        await update.message.reply_text(status)

    async def chat_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        if not update.message or not update.message.text:
            return

        message = update.message.text
        thinking_msg = await update.message.reply_text("ğŸ¸ æ€è€ƒä¸­...")

        try:
            result = await self.core.chat(message)
            await thinking_msg.delete()

            if result["success"]:
                header = f"{result['icon']} *{result['model']}* ({result['latency']}s)\n\n"
                await update.message.reply_text(
                    header + result["content"],
                    parse_mode="Markdown"
                )
            else:
                await update.message.reply_text(
                    f"âŒ æ‰€æœ‰AIå±‚å¤±è´¥\n\n{result['content']}"
                )
        except Exception as e:
            await thinking_msg.delete()
            logger.error(f"Chat error: {e}")
            await update.message.reply_text("âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™")

    async def error_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        logger.error(f"Update {update} caused error {context.error}")

    async def post_init(self, application: Application):
        await self.core.init()
        logger.info("ğŸ¸ Ã–NIKA LI åˆå§‹åŒ–å®Œæˆ")

    def run(self):
        self.application = (
            Application.builder()
            .token(TELEGRAM_TOKEN)
            .post_init(self.post_init)
            .build()
        )

        self.application.add_handler(CommandHandler("start", self.start_command))
        self.application.add_handler(CommandHandler("help", self.help_command))
        self.application.add_handler(CommandHandler("status", self.status_command))
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, self.chat_handler)
        )
        self.application.add_error_handler(self.error_handler)

        logger.info("ğŸ¸ Ã–NIKA LI å¯åŠ¨ä¸­...")
        self.application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    bot = OnikaLiBot()
    bot.run()
